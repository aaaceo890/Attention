# Attention

## 博客知识

1.完全图解`RNN`、`RNN变体`、`Seq2Seq`、`Attention机制`：[知乎专栏](https://zhuanlan.zhihu.com/p/28054589) <br>
补充知识：[LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)<br>

2.Attention存在的问题：[GMIS 2017 | 腾讯AI Lab副主任俞栋：语音识别研究的四大前沿方向](https://mp.weixin.qq.com/s?__biz=MzIzOTg4MjEwNw==&mid=2247483689&idx=1&sn=48c06c6cf270dc6b9db5ae46f78e520c&scene=21#wechat_redirect)

## 论文
1.第一篇将attention用于语音识别的文章：
[J.Chorowski, D.Bahdanau, D.Serdyuk, K.Cho, and Y.Bengio."Attention-based models for speech recognition"](http://papers.nips.cc/paper/5847-attention-based-models-for-speech-recognition.pdf)

2.attention加窗改进，RNN更换为GRU在LVCSR任务上的应用：
[D. Bahdanau, J. Chorowski, D. Serdyuk, P. Brakel, and Y. Bengio,“End-to-end attention- based large vocabulary speech recognition,”]
(https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7472618)

3.最经典的attention语音识别模型：
[W. Chan, N. Jaitly, Q. Le, and O. Vinyals, “Listen, attend and spell: Aneural network for large vocabulary conversational speech recognition”]
（https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7472621）

4.CTC+Attention:
[S. Kim, T. Hori, and S. Watanabe, “Joint CTC-attention based end-to-end speech recognition using multi-task learning”]
(https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7953075)
